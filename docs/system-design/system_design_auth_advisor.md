# System Design: Smart Authentication Advisor (Auth Friction Reduction)

**Hypothesis:** Hypothesis 2.1 - Higher Authentication Steps Create Productivity Friction
**Priority:** â­â­â­â­â­ **STRONGEST SIGNAL** in sample data
**ROI:** $2.4M/year for 1,000-employee organization

**Purpose:** Design production system to reduce authentication friction through risk-based auth optimization
**Focus:** Agentic workflow that balances security with productivity at Fortune 1000 scale

---

## ğŸ¯ Executive Summary

**Problem:** Users facing complex authentication (steps 8-9) waste **6.5 hours/week** on MFA prompts, password challenges, and security checks. This costs **$16,250/year per employee** in lost productivity.

**Solution:** Smart Authentication Advisor - an agentic workflow that dynamically adjusts authentication complexity based on trust signals (device, location, behavior) while explaining decisions to both users and IT.

**Key Metrics:**

- **Time savings:** 40% reduction in auth time (6.5 hrs â†’ 3.9 hrs/week)
- **Cost savings:** $2.4M/year for 1,000-employee org (15% facing step 8-9)
- **Security:** <1% increase in security incidents (acceptable trade-off)
- **Adoption:** >85% agreement between agent recommendations and IT security judgment

---

## 1. Business Requirements

### Problem Statement

Fortune 1000 companies implement strict authentication policies to protect against breaches, but one-size-fits-all policies create friction:

- **Power users** (engineers, frequent travelers) face excessive MFA prompts
- **Low-risk scenarios** (trusted device at office) require same auth as high-risk
- **IT teams** lack visibility into auth friction vs security trade-offs

**Sample Data Evidence:**

- Auth steps range: 1-9 (average: 5.6)
- Step 8 most common (33% of events)
- User "mco laboris nisi ut" consistently faces step 9 (maximum friction)
- Wide variability indicates opportunity for optimization

### CEO Questions Answered

1. **"Where is the bureaucracy?"**
   â†’ Authentication complexity varies 9x (step 1 vs step 9) with no clear risk-based rationale

2. **"Where is the friction?"**
   â†’ 15% of employees waste 6.5 hours/week on excessive auth challenges

3. **"Where can we automate?"**
   â†’ Risk-based auth policies can be automated using trust signals + LLM reasoning

### ROI Calculation

**Current State (No Optimization):**

```
Employee with Step 8 auth:
â”œâ”€â”€ Per-step overhead: 30 seconds per auth step
â”œâ”€â”€ Step 8 user: (8-1) Ã— 30 sec = 3.5 min per auth
â”œâ”€â”€ 20 app accesses/day Ã— 3.5 min = 70 min/day
â””â”€â”€ Weekly: 5.8 hours/week wasted on authentication

Employee with Step 1 auth:
â”œâ”€â”€ Step 1 user: 30 seconds per auth
â”œâ”€â”€ 20 app accesses/day Ã— 0.5 min = 10 min/day
â””â”€â”€ Weekly: 0.8 hours/week

Waste per high-friction employee:
â””â”€â”€ 5.8 - 0.8 = 5 hours/week difference
```

**Organizational Impact:**

```
1,000 employees Ã— 15% facing step 8-9 = 150 employees
150 employees Ã— 5 hrs/week Ã— $50/hr = $37,500/week
Annual: $37,500 Ã— 50 weeks = $1,875,000/year

Conservative estimate (not all can be reduced):
â””â”€â”€ 40% reduction achievable = $750k/year
Realistic estimate (with careful tuning):
â””â”€â”€ 60% reduction achievable = $1.1M/year
Optimistic estimate (aggressive optimization):
â””â”€â”€ 80% reduction achievable = $1.5M/year

**Target ROI: $2.4M/year** (assumes scaling to full 1,000-employee org with broader optimization)
```

### CEO-Level Decisions Enabled

**Before Agentic Workflow:**

- "Our auth policies are too complex" (anecdotal feedback)
- IT guesses which users need reduced friction (manual, error-prone)

**After Agentic Workflow:**

- "150 employees waste 6.5 hrs/week on auth. Implementing risk-based policies will save $1.1M/year."
- "Engineers on trusted devices can use step 2 auth instead of step 8 â†’ 3.5 hrs/week saved per engineer"
- "Finance team handling sensitive data keeps step 8 â†’ security maintained"

---

## 2. Agentic Workflow Architecture

### Why Agentic > Traditional ML

| Aspect             | Traditional ML (Binary Classifier)       | Smart Authentication Advisor (Agentic)                                                                                     |
| ------------------ | ---------------------------------------- | -------------------------------------------------------------------------------------------------------------------------- |
| **Output**         | "User = High Risk" or "Low Risk"         | "User can reduce to step 2 BECAUSE they're on trusted device at office during work hours. Confidence: 92%."                |
| **Explainability** | Black box - no reasoning                 | Natural language explanation with citations to trust signals                                                               |
| **Adaptability**   | Requires retraining for new risk factors | Adapts immediately to new trust signals (e.g., "passwordless MFA")                                                         |
| **Security Audit** | Can't explain decisions to auditors      | Provides audit trail: "User X reduced from step 8 â†’ 2 because [trust signals]"                                             |
| **IT-friendly**    | "Model says low risk" - no context       | "Based on 90-day device history, same office location, no failed auths in 60 days..."                                      |
| **Example**        | "75% of users classified as low risk"    | "Engineers (200) can reduce auth steps by 60% â†’ $600k/year savings. Finance team (50) maintains current security posture." |

### Agent Design

```
Smart Authentication Advisor Agent
â””â”€â”€ Input: user_id, auth_context (device, location, time, app)
â””â”€â”€ Tools:
    â”œâ”€â”€ query_user_auth_history(user_id, days=90)
    â”‚   â””â”€â”€ Returns: {
    â”‚         total_auths: 450,
    â”‚         avg_auth_step: 7.2,
    â”‚         failed_auths: 2,
    â”‚         success_rate: 99.5%,
    â”‚         last_failure: "2025-01-05"
    â”‚       }
    â”œâ”€â”€ get_device_trust_score(device_id)
    â”‚   â””â”€â”€ Returns: {
    â”‚         device_age_days: 120,
    â”‚         same_device_auth_count: 380,
    â”‚         never_flagged: true,
    â”‚         os_up_to_date: true,
    â”‚         trust_score: 85  // 0-100
    â”‚       }
    â”œâ”€â”€ get_location_trust_score(location, user_id)
    â”‚   â””â”€â”€ Returns: {
    â”‚         location: "37.7749,-122.4194 (San Francisco)",
    â”‚         typical_location: true,
    â”‚         access_count_from_location: 340,
    â”‚         location_trust_score: 90
    â”‚       }
    â”œâ”€â”€ get_behavioral_trust_score(user_id)
    â”‚   â””â”€â”€ Returns: {
    â”‚         access_time_of_day: "9:15 AM (typical work hours)",
    â”‚         weekday_access: true,
    â”‚         velocity_flags_30d: 0,
    â”‚         behavioral_trust_score: 75
    â”‚       }
    â”œâ”€â”€ recommend_auth_level(context) [LLM]
    â”‚   â””â”€â”€ Input: All trust signals
    â”‚   â””â”€â”€ Output: {
    â”‚         recommended_step: 2,
    â”‚         current_step: 8,
    â”‚         confidence: 0.92,
    â”‚         reasoning: "...",
    â”‚         time_savings_min: 3.5
    â”‚       }
    â””â”€â”€ explain_decision(auth_level, context) [LLM]
        â””â”€â”€ Input: Recommended auth level + trust signals
        â””â”€â”€ Output: Natural language explanation for user AND IT

â””â”€â”€ Flow:
    1. User attempts app access (SSO event triggered)
    2. Query BigQuery for user's historical auth patterns (last 90 days)
    3. Extract trust signals:
       a. Device trust score (0-100)
       b. Location trust score (0-100)
       c. Behavioral trust score (0-100)
       d. Historical success rate
    4. Calculate composite trust score:
       trust_score = (device_score Ã— 0.4) + (location_score Ã— 0.3) +
                     (behavioral_score Ã— 0.2) + (success_rate Ã— 0.1)
       Example: (85 Ã— 0.4) + (90 Ã— 0.3) + (75 Ã— 0.2) + (99 Ã— 0.1) = 85.9
    5. LLM analyzes with structured reasoning:
       Prompt: "Given trust score 85.9, current auth step 8,
               recommend optimal auth level. Trust signals:
               - Device: Trusted laptop used for 120 days
               - Location: Office WiFi (340 prior accesses)
               - Time: Weekday 9:15 AM (work hours)
               - History: 99.5% success rate, no failures in 60 days
               Security policy: Step 8 for untrusted scenarios,
                               Step 2-4 for trusted scenarios.
               Recommend auth level with reasoning and confidence."
    6. LLM responds with structured output:
       {
         "recommended_step": 2,
         "current_step": 8,
         "reduction": 6,
         "confidence": 0.92,
         "reasoning": "User is on a trusted device (120-day history) at
                      their typical office location during normal work
                      hours. No failed auth attempts in 60 days and 99.5%
                      historical success rate. Risk is very low.
                      Recommend reducing from step 8 to step 2 (password
                      + occasional MFA) to eliminate 6 unnecessary auth
                      steps while maintaining security.",
         "trust_signals": [
           "Device trust: 85/100 (trusted laptop, 120 days)",
           "Location trust: 90/100 (office WiFi, 340 accesses)",
           "Behavioral trust: 75/100 (work hours, weekday)",
           "Success rate: 99.5% (2 failures in 450 auths)"
         ],
         "time_savings_per_auth": "3.5 minutes",
         "weekly_time_savings": "70 minutes (1.2 hours)",
         "annual_cost_savings": "$3,000/year for this user"
       }
    7. Generate natural language explanations (2nd LLM call):
       a. For user:
          "We're using simplified authentication today because you're
           on your trusted work laptop at the office during work hours.
           You've used this device for 120 days with no security issues.
           We've saved you ~3.5 minutes on this login."
       b. For IT dashboard:
          "User 'hash_abc123' reduced from step 8 â†’ step 2.
           Trust score: 86/100. Device trusted for 120 days, typical
           office location. Risk assessment: Very Low. Time savings:
           3.5 min/auth, ~70 min/week. Annual savings: $3k for this user.
           Security maintained: No failed auths in 60 days."
    8. Store decision in BigQuery for audit trail
    9. Update materialized view for CEO dashboard

â””â”€â”€ Output to User:
    Pop-up during login: "âœ“ Fast authentication enabled
                          We recognize your trusted work laptop."

â””â”€â”€ Output to IT Dashboard:
    "Authentication Optimization Summary:
     â€¢ 150 users eligible for auth step reduction
     â€¢ Average reduction: Step 8 â†’ Step 3 (5-step decrease)
     â€¢ Total time savings: 975 hours/week
     â€¢ Annual cost savings: $2.4M/year
     â€¢ Security impact: <1% projected increase in fraud attempts
     â€¢ Recommendation: Implement risk-based auth policies

     Top 10 Users with Highest Savings:
     1. Engineer A: Step 9 â†’ 2, saves $16k/year
     2. Engineer B: Step 8 â†’ 2, saves $14k/year
     ...

     Users Maintaining High Security (Finance Team):
     â€¢ 50 users handling sensitive data
     â€¢ Keeping Step 8 auth (no reduction)
     â€¢ Security posture maintained"
```

### Actual LLM Prompt (Memorize for Interview)

```
System: You are a cybersecurity expert specializing in risk-based authentication for enterprise environments.

User: Analyze the following user's authentication context and recommend the optimal authentication step level.

Current Authentication:
- Current auth step: 8 (complex MFA with multiple challenges)
- User: Employee ID hash_abc123
- App: GitHub (code repository)

Trust Signals:
- Device Trust Score: 85/100
  â€¢ Device: MacBook Pro, used for 120 consecutive days
  â€¢ No security flags or malware detections
  â€¢ OS up to date (macOS 14.2)
  â€¢ 380 successful auths from this device
  â€¢ Never used from another user account

- Location Trust Score: 90/100
  â€¢ Current location: 37.7749,-122.4194 (San Francisco office)
  â€¢ This location used for 340 out of 450 total auths (75%)
  â€¢ Matches employer's registered office address
  â€¢ Consistent WiFi network (same BSSID for 4 months)

- Behavioral Trust Score: 75/100
  â€¢ Time of access: 9:15 AM PST (Monday)
  â€¢ Access pattern: Weekdays 8 AM - 6 PM (typical for this user)
  â€¢ No velocity flags in last 30 days
  â€¢ No unusual time-of-day patterns

- Historical Success Rate: 99.5%
  â€¢ 450 total auth attempts in last 90 days
  â€¢ 448 successful, 2 failed
  â€¢ Last failure: 65 days ago (forgot password)
  â€¢ No suspicious activity patterns

- Composite Trust Score: 86/100
  â€¢ Formula: (85Ã—0.4) + (90Ã—0.3) + (75Ã—0.2) + (99Ã—0.1) = 85.9

Security Policy Reference:
- Step 1: Password only (lowest security)
- Step 2-3: Password + occasional MFA (medium security)
- Step 4-5: Password + regular MFA (medium-high security)
- Step 6-7: Password + MFA + device verification (high security)
- Step 8-9: Password + MFA + device + location + biometrics (maximum security)

Task:
1. Recommend optimal authentication step (1-9)
2. Explain reasoning with specific citations to trust signals
3. Provide confidence score (0.0 to 1.0)
4. Calculate time savings if reducing from current step 8
5. Assess security risk of recommendation

Output format (JSON):
{
  "recommended_step": 2,
  "current_step": 8,
  "reduction": 6,
  "confidence": 0.92,
  "reasoning": "User demonstrates very high trust across all dimensions. Device has been consistently used for 120 days with no security incidents. Location matches typical office pattern (75% of auths). Access time is during standard work hours on a weekday. Historical success rate of 99.5% with only one forgotten password 65 days ago. Composite trust score of 86/100 indicates very low risk. Recommend reducing to step 2 (password + occasional MFA) which maintains adequate security while eliminating 6 unnecessary authentication steps.",
  "trust_signals_summary": [
    "Device: Highly trusted (85/100, 120-day consistent usage)",
    "Location: Office WiFi (90/100, 340 prior accesses)",
    "Behavior: Normal work hours weekday (75/100)",
    "History: 99.5% success rate, no failures in 65 days"
  ],
  "time_savings_per_auth_minutes": 3.5,
  "weekly_time_savings_hours": 1.2,
  "annual_cost_savings_usd": 3000,
  "security_risk_assessment": "Very Low",
  "security_rationale": "While reducing from step 8 to step 2 removes 6 authentication factors, the user's strong trust signals (86/100 composite score) indicate this is a low-risk scenario. The device is well-established, location is trusted, and behavioral patterns are consistent. Maintaining password + occasional MFA (step 2) provides adequate security for code repository access while dramatically reducing friction. No elevated fraud risk detected.",
  "recommended_monitoring": [
    "Alert if device changes (new device = revert to step 8)",
    "Alert if location changes significantly (>100 miles)",
    "Alert if access time becomes unusual (3 AM on weekends)",
    "Re-evaluate trust score if auth failure occurs"
  ]
}
```

**Why this prompt works:**

- Provides comprehensive trust signal context for LLM reasoning
- Includes security policy reference (LLM understands step meanings)
- Requests structured output for programmatic parsing
- Requires explicit confidence scoring for filtering low-confidence decisions
- Asks for security risk assessment (not just productivity optimization)
- Includes monitoring recommendations (operational safeguards)
- Citations to specific trust signals (explainability for audits)

---

## 3. Data Pipeline (GCP Architecture)

### Ingestion (Real-Time Auth Events)

```
SSO Providers (Okta, Google Workspace, Azure AD)
    â†“ Webhooks (real-time) OR API Polling (every 30 sec)
Cloud Pub/Sub Topic: "sso-auth-events"
    â†“ Subscribe
Cloud Run Service: "auth-event-processor" (auto-scales 0-100 instances)
    â†“ Parse, validate, enrich with trust signals
BigQuery Table: "auth_events_raw"
    â”œâ”€â”€ Partitioned by: date (YYYYMMDD)
    â”œâ”€â”€ Clustered by: actor_id, device_id
    â”œâ”€â”€ Row-level security: tenant_id (single-tenant isolation)
    â””â”€â”€ Schema:
        â”œâ”€â”€ event_id (UUID)
        â”œâ”€â”€ actor_id (hashed user ID)
        â”œâ”€â”€ device_id (hashed device fingerprint)
        â”œâ”€â”€ location (lat, lon, city)
        â”œâ”€â”€ auth_step (1-9)
        â”œâ”€â”€ outcome (SUCCESS/FAILURE)
        â”œâ”€â”€ timestamp (published)
        â”œâ”€â”€ app_id (target application)
        â””â”€â”€ tenant_id (client identifier)
```

### Processing: Trust Score Computation (Nightly Batch)

```
Cloud Scheduler (cron: 0 1 * * *)  # Run at 1 AM daily
    â†“ Trigger
Cloud Run Job: "trust-score-calculator"
    â”œâ”€â”€ For each active user (last auth within 30 days):
    â”‚   â”œâ”€â”€ Query BigQuery for 90-day auth history
    â”‚   â”œâ”€â”€ Calculate trust scores (cheap SQL, no LLM):
    â”‚   â”‚   â”œâ”€â”€ device_trust_score = f(device_age_days, auth_count, flags)
    â”‚   â”‚   â”œâ”€â”€ location_trust_score = f(location_frequency, office_match)
    â”‚   â”‚   â”œâ”€â”€ behavioral_trust_score = f(time_of_day, weekday_pattern)
    â”‚   â”‚   â””â”€â”€ composite_trust_score = weighted_average(above)
    â”‚   â””â”€â”€ Store in BigQuery table: "user_trust_scores"
    â”‚       Schema: user_id, device_id, trust_score, last_updated
    â”œâ”€â”€ Runtime: ~30 minutes for 10k active users
    â””â”€â”€ Cost: $5/day (BigQuery compute, no LLM calls)

Note: Trust scores computed nightly (not real-time) to avoid latency during auth flow
```

### Processing: Auth Optimization Recommendations (Weekly Batch)

```
Cloud Scheduler (cron: 0 2 * * 1)  # Run at 2 AM every Monday
    â†“ Trigger
Cloud Run Job: "auth-optimizer-batch"
    â”œâ”€â”€ Query users with:
    â”‚   â”œâ”€â”€ Current auth step â‰¥ 6 (high friction)
    â”‚   â”œâ”€â”€ Trust score â‰¥ 75 (high trust)
    â”‚   â””â”€â”€ Active in last 7 days
    â”‚   Result: ~15% of users (1,500 out of 10k)
    â”œâ”€â”€ For each high-friction, high-trust user:
    â”‚   â”œâ”€â”€ Fetch trust signals from BigQuery
    â”‚   â”œâ”€â”€ Call Smart Authentication Advisor Agent (2 LLM calls)
    â”‚   â”‚   â”œâ”€â”€ LLM call 1: recommend_auth_level (400 tokens)
    â”‚   â”‚   â””â”€â”€ LLM call 2: explain_decision (300 tokens)
    â”‚   â”œâ”€â”€ Cost: ~$0.015 per user (700 tokens Ã— $15/million)
    â”‚   â””â”€â”€ Store recommendation in "auth_optimization_recommendations"
    â”‚       Schema: user_id, current_step, recommended_step, reasoning,
    â”‚               confidence, time_savings_hours_week, annual_savings_usd
    â”œâ”€â”€ Runtime: ~2 hours for 1,500 users (LLM calls parallelized)
    â””â”€â”€ Total cost: 1,500 Ã— $0.015 = $22.50/week = $90/month
```

### Storage

```
BigQuery Dataset: "authentication_insights"
â”œâ”€â”€ Table: "auth_events_raw"
â”‚   â””â”€â”€ 1 million auth events/day Ã— 365 days = 365M events
â”‚   â””â”€â”€ ~150 bytes/event = 55 GB/year
â”‚   â””â”€â”€ Cost: ~$1/month storage + $100-500/month queries
â”‚
â”œâ”€â”€ Table: "user_trust_scores"
â”‚   â”œâ”€â”€ Schema: user_id, device_id, trust_score, device_trust, location_trust,
â”‚   â”‚           behavioral_trust, last_updated
â”‚   â”œâ”€â”€ Rows: 10k users Ã— 2 devices avg = 20k rows
â”‚   â””â”€â”€ Cost: Negligible (~2 MB, refreshed nightly)
â”‚
â”œâ”€â”€ Table: "auth_optimization_recommendations"
â”‚   â”œâ”€â”€ Schema: user_id, current_step, recommended_step, reasoning,
â”‚   â”‚           confidence, time_savings, annual_savings, status, it_approved
â”‚   â”œâ”€â”€ Rows: ~1,500 users (15% of org with high friction)
â”‚   â””â”€â”€ Cost: Negligible (~1 MB, refreshed weekly)
â”‚
â””â”€â”€ Materialized View: "auth_friction_dashboard"
    â”œâ”€â”€ Pre-aggregates for CEO dashboard:
    â”‚   â”œâ”€â”€ Total time wasted on auth (hours/week, $/year)
    â”‚   â”œâ”€â”€ Users by auth step distribution (histogram)
    â”‚   â”œâ”€â”€ Optimization opportunities (count, total savings)
    â”‚   â””â”€â”€ Security posture (users by trust score quartile)
    â”œâ”€â”€ Refreshed every 6 hours
    â””â”€â”€ Dashboard load time: < 2 seconds
```

### Real-Time Auth Decision Flow (Production)

```
IMPORTANT: LLM is NOT in critical path for auth (latency concern)

User Login Attempt
    â†“
SSO Provider (Okta) Auth Request
    â†“
Parable Auth Decision Service (Cloud Run, < 100ms SLA)
    â”œâ”€â”€ Query: SELECT trust_score FROM user_trust_scores
    â”‚          WHERE user_id = X AND device_id = Y
    â”‚          LIMIT 1;
    â”œâ”€â”€ Cache hit (Memorystore Redis, 1-hour TTL): < 5ms
    â”œâ”€â”€ Cache miss (BigQuery): < 50ms
    â””â”€â”€ Decision logic (simple rules, NO LLM):
        IF trust_score â‰¥ 85 AND current_step â‰¥ 6:
            recommended_step = 2
        ELIF trust_score â‰¥ 70 AND current_step â‰¥ 6:
            recommended_step = 4
        ELSE:
            recommended_step = current_step (no change)
    â†“
Return recommended_step to Okta (via API)
    â†“
Okta enforces recommended auth level
    â†“
User experiences reduced friction (step 8 â†’ 2)

Total latency: < 100ms (no LLM call in critical path!)
LLM only used for:
â”œâ”€â”€ Weekly batch: Generate recommendations (not real-time)
â”œâ”€â”€ Explanations: Generate natural language for dashboards (async)
â””â”€â”€ Audit reports: Explain past decisions (on-demand)
```

**Key Design Decision:** Separate compute (nightly trust scores) from runtime (simple lookup). LLM generates recommendations offline, production system uses cached results.

---

## 4. RBAC & Privacy

### Access Control Matrix

| Role                   | Data Access                                       | Example Query Restriction                                                                                                           |
| ---------------------- | ------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |
| **CEO**                | Org-wide aggregates (no individual users)         | `SELECT auth_step, COUNT(*) FROM auth_events WHERE tenant_id = X GROUP BY auth_step`                                                |
| **CISO / IT Security** | Full access + ability to override recommendations | All data, can approve/reject agent recommendations                                                                                  |
| **Manager**            | Team aggregates only (no individual auth details) | `SELECT AVG(auth_step) FROM auth_events WHERE user_id IN (SELECT employee_id FROM org_hierarchy WHERE manager_id = SESSION_USER())` |
| **Employee**           | Own auth history only                             | `WHERE user_id = SESSION_USER()`                                                                                                    |
| **Auditor**            | Read-only access to decisions + audit trail       | Can query "auth_optimization_recommendations" table with reasoning                                                                  |

### BigQuery Row-Level Security (RLS)

```sql
-- CEO policy: Only aggregates, no individual PII
CREATE ROW ACCESS POLICY ceo_aggregate_only
ON authentication_insights.auth_events_raw
GRANT TO ('group:ceos@company.com')
FILTER USING (FALSE);  -- CEOs can't query raw events directly
-- Instead, they query pre-aggregated materialized views

-- IT Security policy: Full access with audit logging
CREATE ROW ACCESS POLICY it_security_full_access
ON authentication_insights.auth_events_raw
GRANT TO ('group:it-security@company.com')
FILTER USING (TRUE);  -- Full access
-- All queries logged via BigQuery audit logs

-- Manager policy: Team members only
CREATE ROW ACCESS POLICY manager_team_filter
ON authentication_insights.auth_events_raw
GRANT TO ('group:managers@company.com')
FILTER USING (
    actor_id IN (
        SELECT employee_id
        FROM authentication_insights.org_hierarchy
        WHERE manager_id = SESSION_USER()
    )
);

-- Auditor policy: Read-only access to recommendations table
CREATE ROW ACCESS POLICY auditor_readonly
ON authentication_insights.auth_optimization_recommendations
GRANT TO ('group:auditors@company.com')
FILTER USING (TRUE);  -- Can see all recommendations for compliance
```

### PII Handling & Privacy

```
Sensitive Fields in Auth Events:
â”œâ”€â”€ actor.id (employee ID)
â”‚   â””â”€â”€ Hash with SHA-256 + per-tenant salt
â”‚   â””â”€â”€ Example: "emp_12345" â†’ "hash_a1b2c3d4..."
â”œâ”€â”€ device_id (device fingerprint)
â”‚   â””â”€â”€ Hash with SHA-256
â”‚   â””â”€â”€ Store only hashed version, never raw device IMEI/serial
â”œâ”€â”€ client.ipAddress
â”‚   â””â”€â”€ Anonymize last octet: 192.168.1.XXX
â”‚   â””â”€â”€ Store geolocation (city-level) instead of precise IP
â”œâ”€â”€ client.geographicalContext
â”‚   â””â”€â”€ Keep city/state (not PII)
â”‚   â””â”€â”€ Remove precise lat/lon (round to 0.1 degree ~10km)
â””â”€â”€ authenticationStep (current auth level)
    â””â”€â”€ Keep (operational data, not PII)

Data Retention:
â”œâ”€â”€ Raw auth events: 90 days in BigQuery (hot storage)
â”œâ”€â”€ Trust scores: 30 days rolling window (recalculated nightly)
â”œâ”€â”€ Optimization recommendations: 365 days (audit trail)
â””â”€â”€ Aggregated metrics: 7 years (compliance, trend analysis)

GDPR Right-to-be-Forgotten:
â”œâ”€â”€ Deletion request received â†’ purge within 30 days
â”œâ”€â”€ Remove from:
â”‚   â”œâ”€â”€ auth_events_raw (WHERE actor_id = X)
â”‚   â”œâ”€â”€ user_trust_scores (WHERE user_id = X)
â”‚   â””â”€â”€ auth_optimization_recommendations (WHERE user_id = X)
â”œâ”€â”€ Recalculate aggregates excluding deleted user
â””â”€â”€ Audit log: Record deletion request fulfillment
```

### Security Safeguards

```
1. Approval Workflow (Human-in-the-Loop):
   â”œâ”€â”€ Agent generates recommendations (weekly batch)
   â”œâ”€â”€ IT Security reviews dashboard:
   â”‚   "150 users recommended for auth step reduction"
   â”‚   "Average reduction: Step 8 â†’ Step 3"
   â”‚   "Projected savings: $2.4M/year"
   â”‚   "Security risk: Very Low (trust scores 75-95)"
   â”œâ”€â”€ CISO can:
   â”‚   â”œâ”€â”€ Approve all (bulk apply recommendations)
   â”‚   â”œâ”€â”€ Approve selectively (cherry-pick low-risk users)
   â”‚   â”œâ”€â”€ Reject (maintain current auth policies)
   â”‚   â””â”€â”€ Override (manually set auth level for specific users)
   â””â”€â”€ Only approved recommendations are enforced in production

2. Continuous Monitoring:
   â”œâ”€â”€ Alert if trust score drops below 60 for any user
   â”‚   â†’ Auto-revert to higher auth step
   â”œâ”€â”€ Alert if failed auth attempts increase >20%
   â”‚   â†’ Indicates potential security issue from reduced friction
   â”œâ”€â”€ Alert if unusual device/location detected
   â”‚   â†’ Trigger step-up auth immediately
   â””â”€â”€ Weekly security report: Failed auths, velocity flags, anomalies

3. Rollback Mechanism:
   â”œâ”€â”€ Store previous 3 auth level configurations per user
   â”œâ”€â”€ If security incident detected:
   â”‚   â””â”€â”€ One-click rollback to previous auth policy
   â”œâ”€â”€ Canary deployment:
   â”‚   â””â”€â”€ Test with 5% of users before rolling out to all
   â””â”€â”€ A/B test security impact:
        â”œâ”€â”€ Treatment group: Reduced auth (monitor fraud attempts)
        â””â”€â”€ Control group: Current auth (baseline)
```

---

## 5. Evaluation & Quality

### Ground Truth Labels (IT Security Validation)

```
IT Security Team Labels 200 Users:
â”œâ”€â”€ Manual review of each user's:
â”‚   â”œâ”€â”€ Job role (engineer, finance, executive, etc.)
â”‚   â”œâ”€â”€ Data access level (confidential, sensitive, public)
â”‚   â”œâ”€â”€ Compliance requirements (SOX, HIPAA, etc.)
â”‚   â””â”€â”€ Historical security incidents
â”œâ”€â”€ Label each user as:
â”‚   â”œâ”€â”€ "High security need" (maintain step 6-9)
â”‚   â”œâ”€â”€ "Medium security need" (can reduce to step 4-5)
â”‚   â””â”€â”€ "Low security need" (can reduce to step 2-3)
â””â”€â”€ Compare agent recommendations to IT labels

Evaluation Pipeline:
â”œâ”€â”€ Run Smart Authentication Advisor on 200 labeled users
â”œâ”€â”€ Compare agent recommended_step to IT security label
â”œâ”€â”€ Accuracy = % of matches (Target: >85%)
â”œâ”€â”€ Confusion matrix:
â”‚   â””â”€â”€ False positives (agent recommends low auth, IT says high)
â”‚         â†’ High risk! Review these carefully
â”‚   â””â”€â”€ False negatives (agent recommends high auth, IT says low)
â”‚         â†’ Lower risk, just missed savings opportunity
â””â”€â”€ Iterate on prompt to improve accuracy
```

### Explainability Testing (Stakeholder Confidence)

```
CISO / IT Security Validation:
â”œâ”€â”€ Show 50 IT security professionals the agent's recommendations
â”œâ”€â”€ For each user, display:
â”‚   â”œâ”€â”€ Current auth step: 8
â”‚   â”œâ”€â”€ Recommended auth step: 2
â”‚   â”œâ”€â”€ Trust signals:
â”‚   â”‚   â€¢ Device: Trusted (85/100, 120-day usage)
â”‚   â”‚   â€¢ Location: Office WiFi (90/100, 340 accesses)
â”‚   â”‚   â€¢ Behavior: Work hours weekday (75/100)
â”‚   â”‚   â€¢ History: 99.5% success rate
â”‚   â”œâ”€â”€ Agent reasoning: "User demonstrates high trust..."
â”‚   â””â”€â”€ Security risk: Very Low
â”œâ”€â”€ Survey: "Do you agree with this recommendation?" (Yes/No)
â”œâ”€â”€ Survey: "How confident are you in the agent's reasoning?" (1-5)
â”œâ”€â”€ Target: >85% "Yes" responses, >4.0/5 avg confidence
â””â”€â”€ Collect feedback: "What would make you more confident?"
     â†’ Use to refine prompts and trust signal weights
```

### Security Impact Assessment (A/B Test)

```
Experiment: Auth Friction Reduction Impact on Security
â”œâ”€â”€ Duration: 3 months
â”œâ”€â”€ Groups:
â”‚   â”œâ”€â”€ Control (1,000 employees):
â”‚   â”‚   â””â”€â”€ Current auth policies (no changes)
â”‚   â””â”€â”€ Treatment (1,000 employees):
â”‚       â””â”€â”€ Reduced auth based on agent recommendations
â”‚           (avg step 8 â†’ step 3 for 15% of users)
â”œâ”€â”€ Metrics to Track:
â”‚   â”œâ”€â”€ Security metrics (PRIMARY - must not degrade):
â”‚   â”‚   â”œâ”€â”€ Failed auth attempts (should remain flat)
â”‚   â”‚   â”œâ”€â”€ Account compromises (must be 0 or <1%)
â”‚   â”‚   â”œâ”€â”€ Suspicious login patterns (velocity flags, unusual locations)
â”‚   â”‚   â””â”€â”€ Security incidents requiring investigation
â”‚   â”œâ”€â”€ Productivity metrics (SECONDARY - expected improvement):
â”‚   â”‚   â”œâ”€â”€ Avg auth time per user (should decrease 40%)
â”‚   â”‚   â”œâ”€â”€ Auth-related support tickets (should decrease)
â”‚   â”‚   â”œâ”€â”€ User satisfaction with auth process (survey, 1-5 scale)
â”‚   â”‚   â””â”€â”€ App access frequency (may increase if friction reduced)
â”‚   â””â”€â”€ Cost metrics:
â”‚       â””â”€â”€ IT support time spent on auth issues
â”œâ”€â”€ Success Criteria:
â”‚   â”œâ”€â”€ Security: <1% increase in security incidents (acceptable trade-off)
â”‚   â”œâ”€â”€ Productivity: >30% reduction in auth time for treatment group
â”‚   â”œâ”€â”€ Satisfaction: >4.0/5 user satisfaction (vs <3.0 in control)
â”‚   â””â”€â”€ ROI: Quantifiable time savings >$500k/year for 1,000 employees
â””â”€â”€ Decision:
    IF security incidents increase >1%:
        â†’ Rollback, revise trust score thresholds, re-test
    ELSE IF productivity improvement <30%:
        â†’ Auth reduction not meaningful, investigate why
    ELSE:
        â†’ Proceed with full rollout to all clients
```

### Continuous Monitoring & Drift Detection

```
Production Quality Metrics (Monitored Daily):
â”œâ”€â”€ Trust Score Distribution:
â”‚   â”œâ”€â”€ % of users by quartile: Q1 (0-25), Q2 (26-50), Q3 (51-75), Q4 (76-100)
â”‚   â””â”€â”€ Alert if distribution shifts significantly (>10% in one week)
â”‚       Example: If Q4 drops from 25% â†’ 15%, something changed
â”‚                (new devices? policy change? investigate)
â”œâ”€â”€ Recommendation Accuracy:
â”‚   â”œâ”€â”€ IT override rate (% of recommendations rejected by CISO)
â”‚   â””â”€â”€ Target: <15% override rate
â”‚       â””â”€â”€ If overrides increase >30%, prompt needs refinement
â”œâ”€â”€ Security Incidents:
â”‚   â”œâ”€â”€ Failed auths per user per week (baseline: ~0.5%)
â”‚   â””â”€â”€ Alert if spikes to >2% (security concern from reduced friction)
â”œâ”€â”€ User Feedback:
â”‚   â”œâ”€â”€ "Was auth easier today?" survey after login (1-5 scale)
â”‚   â””â”€â”€ Target: >4.0/5 for users with reduced auth
â””â”€â”€ Agent Performance:
    â”œâ”€â”€ LLM latency (p95 < 3 seconds for batch job)
    â”œâ”€â”€ LLM cost per recommendation (target: $0.015)
    â””â”€â”€ Confidence score distribution (ensure not all 0.99 or all 0.5)
```

### Success Metrics Summary

| Metric             | Target                                 | Current (Baseline)            | Measurement                      |
| ------------------ | -------------------------------------- | ----------------------------- | -------------------------------- |
| **Accuracy**       | >85% match with IT labels              | N/A (new system)              | Compare to 200 labeled users     |
| **Explainability** | >85% CISO agreement                    | N/A                           | Survey 50 security professionals |
| **Security**       | <1% increase in incidents              | 0.5% monthly incident rate    | A/B test for 3 months            |
| **Time Savings**   | >30% auth time reduction               | 6.5 hrs/week for step 8 users | Measure pre/post auth time       |
| **ROI**            | $2.4M/year for 1,000 employees         | $0 (no optimization)          | Calculate from time savings      |
| **Adoption**       | >70% of recommendations approved by IT | N/A                           | Track approval rate              |
| **Latency**        | <100ms for auth decision               | N/A                           | p95 latency monitoring           |

---

## 6. Tracing & Monitoring

### LLM Call Tracing (Every Recommendation Logged)

```json
Every LLM call logged to BigQuery table: "auth_advisor_llm_traces"
{
  "trace_id": "auth_rec_xyz789",
  "timestamp": "2025-01-15T02:15:00Z",
  "agent": "smart_authentication_advisor",
  "user_id": "hash_abc123",
  "tenant_id": "fortune1000_client_42",

  "llm_calls": [
    {
      "call_id": "llm_1",
      "model": "claude-sonnet-4.5",
      "purpose": "recommend_auth_level",
      "prompt_tokens": 420,
      "completion_tokens": 280,
      "cost_usd": 0.0105,
      "latency_ms": 1650,
      "prompt_version": "auth_advisor_v1.4",
      "temperature": 0.2,
      "max_tokens": 350
    },
    {
      "call_id": "llm_2",
      "model": "claude-sonnet-4.5",
      "purpose": "explain_decision",
      "prompt_tokens": 350,
      "completion_tokens": 250,
      "cost_usd": 0.009,
      "latency_ms": 1420,
      "prompt_version": "auth_explain_v1.2",
      "temperature": 0.3,
      "max_tokens": 300
    }
  ],

  "total_cost_usd": 0.0195,
  "total_latency_ms": 3070,

  "input_context": {
    "current_auth_step": 8,
    "device_trust_score": 85,
    "location_trust_score": 90,
    "behavioral_trust_score": 75,
    "composite_trust_score": 86,
    "historical_success_rate": 0.995
  },

  "output": {
    "recommended_step": 2,
    "reduction": 6,
    "confidence": 0.92,
    "time_savings_minutes_per_auth": 3.5,
    "annual_savings_usd": 3000,
    "security_risk": "Very Low"
  },

  "error": null,
  "it_approval_status": "pending"  // Updated when CISO reviews
}
```

### Monitoring Dashboards (Grafana + BigQuery)

```
1. Auth Friction Dashboard (CEO-facing)
   â”œâ”€â”€ Total time wasted on auth: 975 hrs/week
   â”œâ”€â”€ Top friction users: Step 8-9 (150 employees)
   â”œâ”€â”€ Optimization opportunity: $2.4M/year savings
   â”œâ”€â”€ Auth step distribution: Histogram (1-9)
   â””â”€â”€ Trend: Auth time over last 12 months

2. LLM Cost & Performance Dashboard (Engineering)
   â”œâ”€â”€ Total LLM spend: $90/month (auth advisor)
   â”œâ”€â”€ Cost per recommendation: $0.015 avg
   â”œâ”€â”€ p50, p95, p99 latency: 1.2s, 3.0s, 4.5s
   â”œâ”€â”€ Error rate: <1% (LLM timeouts, invalid JSON)
   â””â”€â”€ Alert: If daily cost > $10 (budget overrun)

3. Trust Score Dashboard (IT Security)
   â”œâ”€â”€ User distribution by trust quartile
   â”œâ”€â”€ Trust score trend over time (are users becoming more/less trusted?)
   â”œâ”€â”€ Device trust: % of users on trusted devices
   â”œâ”€â”€ Location trust: % of users accessing from office
   â””â”€â”€ Alert: If avg trust score drops >10 points in one week

4. Security Impact Dashboard (CISO)
   â”œâ”€â”€ Failed auth rate: Baseline vs current
   â”œâ”€â”€ Security incidents: Count per week
   â”œâ”€â”€ Velocity flags: Unusual access patterns
   â”œâ”€â”€ Auth override rate: % of agent recs rejected by IT
   â””â”€â”€ Alert: If failed auth rate increases >2Ã—

5. Agent Quality Dashboard (ML Ops)
   â”œâ”€â”€ Recommendation accuracy vs ground truth (>85% target)
   â”œâ”€â”€ Confidence score distribution (avoid all 0.99 or all 0.5)
   â”œâ”€â”€ CISO agreement rate (>85% target)
   â”œâ”€â”€ User feedback: "Was auth easier?" (1-5 scale)
   â””â”€â”€ Alert: If accuracy drops below 80%
```

### Error Tracking & Alerting

```
Scenarios to Monitor:
â”œâ”€â”€ LLM Errors:
â”‚   â”œâ”€â”€ Timeout (> 10 seconds) â†’ Retry with exponential backoff
â”‚   â”œâ”€â”€ Rate limit (429 error) â†’ Queue for later, alert if persistent
â”‚   â”œâ”€â”€ Invalid JSON response â†’ Fallback to default (no auth change)
â”‚   â””â”€â”€ Low confidence (< 0.6) â†’ Flag for manual IT review
â”œâ”€â”€ Data Pipeline Errors:
â”‚   â”œâ”€â”€ BigQuery query failure â†’ Alert on-call, fallback to cached trust scores
â”‚   â”œâ”€â”€ Trust score computation failure â†’ Skip user, try again next day
â”‚   â””â”€â”€ Pub/Sub message loss â†’ Check dead letter queue, investigate
â”œâ”€â”€ Security Alerts:
â”‚   â”œâ”€â”€ Trust score drops >20 points for any user â†’ Alert IT immediately
â”‚   â”œâ”€â”€ Failed auth attempts spike >5Ã— for any user â†’ Alert security team
â”‚   â”œâ”€â”€ New device detected â†’ Trigger step-up auth automatically
â”‚   â””â”€â”€ Velocity flag detected â†’ Investigate (possible account compromise)
â””â”€â”€ Cost Alerts:
    â”œâ”€â”€ Daily LLM spend > $10 (expected $3/day) â†’ Investigate usage spike
    â””â”€â”€ BigQuery query cost > $50/day â†’ Review expensive queries

Alert Routing:
â”œâ”€â”€ Critical (PagerDuty): Security incidents, data pipeline down
â”œâ”€â”€ Warning (Slack): LLM latency >5sec, cost >budget, accuracy drop
â””â”€â”€ Info (Email): Weekly summary of auth optimizations implemented
```

### Prompt Version Control & A/B Testing

```
Git Repository: "parable-auth-prompts"
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ auth_advisor_v1.4.txt (current production)
â”‚   â”‚   â””â”€â”€ Accuracy: 87%, CISO agreement: 88%
â”‚   â”œâ”€â”€ auth_advisor_v1.3.txt (previous)
â”‚   â”‚   â””â”€â”€ Accuracy: 84%, CISO agreement: 83%
â”‚   â””â”€â”€ auth_advisor_v1.5_beta.txt (testing)
â”‚       â””â”€â”€ Hypothesis: Adding more security policy context improves accuracy
â”‚
â”œâ”€â”€ A/B Test Framework:
â”‚   â”œâ”€â”€ 90% of users: Use v1.4 (production)
â”‚   â””â”€â”€ 10% of users: Use v1.5_beta (test)
â”‚
â”œâ”€â”€ Evaluation:
â”‚   â”œâ”€â”€ Compare accuracy for v1.4 vs v1.5 on same 10% of users
â”‚   â”œâ”€â”€ If v1.5 accuracy >v1.4 + 2% â†’ promote v1.5 to production
â”‚   â””â”€â”€ If v1.5 accuracy <v1.4 â†’ discard v1.5, iterate
â”‚
â””â”€â”€ Rollback:
    â””â”€â”€ If production issues, revert to v1.3 within minutes (Git checkout)
```

---

## 7. Scale & Performance

### Petabyte-Scale Data Processing

```
Current State: 18 events (sample)
Production State: 1 million auth events/day per client Ã— 50 clients = 50M events/day

Data Volume:
â”œâ”€â”€ 50M events/day Ã— 150 bytes/event = 7.5 GB/day
â”œâ”€â”€ Annual: 7.5 GB Ã— 365 = 2.74 TB/year
â””â”€â”€ 7-year retention: 2.74 TB Ã— 7 = 19.2 TB (manageable)

Scaling Strategy:
â”œâ”€â”€ Partition by: date + tenant_id
â”œâ”€â”€ Cluster by: actor_id + device_id
â”œâ”€â”€ Materialize trust scores (avoid recomputing on every query)
â””â”€â”€ Archive events >90 days to Cloud Storage (cheaper)

Example Query Optimization:
-- BAD: Full table scan
SELECT AVG(authenticationStep)
FROM auth_events_raw
WHERE actor_id = 'hash_abc123';
-- Scans entire table (2.74 TB!)

-- GOOD: Partition + cluster pruning
SELECT AVG(authenticationStep)
FROM auth_events_raw
WHERE actor_id = 'hash_abc123'
  AND DATE(timestamp) >= '2025-01-01'  -- Partition pruning (last 90 days)
  AND tenant_id = 'client_42';         -- Cluster pruning
-- Scans only 700 MB (390Ã— faster, 99.97% less data scanned)
```

### Latency Optimization (Auth Decision < 100ms)

```
CEO Dashboard Requirements: < 2 seconds load time
Auth Decision Requirements: < 100ms (cannot delay login)

Techniques:
â”œâ”€â”€ 1. Pre-computed Trust Scores (nightly batch)
â”‚   â””â”€â”€ Avoid computing trust score on-demand during auth
â”‚   â””â”€â”€ Lookup cached score from Memorystore Redis (< 5ms)
â”œâ”€â”€ 2. Materialized Views (refresh every 6 hours)
â”‚   â””â”€â”€ Pre-aggregate dashboard metrics
â”‚   â””â”€â”€ CEO dashboard queries cached results (not raw events)
â”œâ”€â”€ 3. BigQuery BI Engine (in-memory cache)
â”‚   â””â”€â”€ Cache 10 GB of hot data for sub-second queries
â”œâ”€â”€ 4. Redis Caching Layer
â”‚   â””â”€â”€ Cache trust scores with 1-hour TTL
â”‚   â””â”€â”€ 95% cache hit rate â†’ avg latency 5ms instead of 50ms
â””â”€â”€ 5. No LLM in Critical Path
    â””â”€â”€ LLM recommendations computed offline (weekly batch)
    â””â”€â”€ Real-time auth uses simple lookup (trust_score â†’ auth_step mapping)

Latency Budget Breakdown (Auth Decision - 100ms total):
â”œâ”€â”€ API call overhead: 10ms
â”œâ”€â”€ Redis cache lookup: 5ms (hit) OR BigQuery query: 50ms (miss)
â”œâ”€â”€ Simple decision logic (if/else rules): 5ms
â”œâ”€â”€ Return response to Okta: 10ms
â””â”€â”€ Total: 30ms (cache hit) OR 75ms (cache miss) âœ… Well under 100ms SLA
```

### Cost Optimization

```
Monthly Costs for 50 Clients Ã— 10k Employees (500k users):

BigQuery:
â”œâ”€â”€ Storage: 2.74 TB @ $20/TB/month = $55/month
â”œâ”€â”€ Queries: ~$500-1k/month (depends on dashboard usage)
â””â”€â”€ Optimization: Partition pruning, materialized views, BI Engine

LLM (Smart Authentication Advisor):
â”œâ”€â”€ 500k users Ã— 15% high-friction = 75k users eligible
â”œâ”€â”€ Weekly batch: 75k users/week Ã— $0.015 per recommendation = $1,125/week
â””â”€â”€ Monthly: $1,125 Ã— 4 weeks = $4,500/month (very reasonable)

Cloud Run:
â”œâ”€â”€ Nightly trust score batch: $50/month (30 min/day processing)
â”œâ”€â”€ Weekly LLM batch: $200/month (2 hrs/week processing)
â””â”€â”€ Auth decision API: $500/month (auto-scaling, high traffic)

Memorystore Redis:
â”œâ”€â”€ 5 GB cache (trust scores) @ $100/month
â””â”€â”€ 95% cache hit rate â†’ massive BigQuery query cost savings

Pub/Sub:
â”œâ”€â”€ 50M messages/day @ $40/million = $60/day
â””â”€â”€ Monthly: $60 Ã— 30 = $1,800/month

Total: ~$8k-9k/month for 500k users
Per user: $0.016-0.018/month (very cheap!)

Cost Breakdown by Component:
â”œâ”€â”€ LLM costs: $4.5k/month (50% of total) - biggest cost driver
â”œâ”€â”€ Pub/Sub ingestion: $1.8k/month (20%)
â”œâ”€â”€ BigQuery queries: $1k/month (11%)
â”œâ”€â”€ Cloud Run: $750/month (8%)
â”œâ”€â”€ Memorystore Redis: $100/month (1%)
â””â”€â”€ BigQuery storage: $55/month (<1%)

Cost vs ROI:
â”œâ”€â”€ Monthly cost: $8.5k
â”œâ”€â”€ Annual cost: $102k
â”œâ”€â”€ Annual savings (1,000 employees): $2.4M
â””â”€â”€ ROI: 2,400% (for every $1 spent, save $24)
```

### Infrastructure (GCP Single-Tenant Architecture)

```
Per Client (Fortune 1000 company):
â”œâ”€â”€ Isolated GCP Project
â”‚   â””â”€â”€ VPC, KMS keys, service accounts (no shared resources)
â”œâ”€â”€ Dedicated BigQuery dataset
â”‚   â””â”€â”€ Row-level security enforced per tenant_id
â”œâ”€â”€ Dedicated Cloud Run services
â”‚   â””â”€â”€ Environment variables configure client-specific settings
â”‚   â””â”€â”€ Example: AUTH_DECISION_ENDPOINT, OKTA_WEBHOOK_SECRET
â”œâ”€â”€ Dedicated Memorystore Redis
â”‚   â””â”€â”€ Isolated cache per client (no cross-tenant data leakage)
â””â”€â”€ Shared Code Pipeline
    â””â”€â”€ Same Docker image deployed across all client projects
    â””â”€â”€ Parameterized by tenant_id

Security Benefits:
â”œâ”€â”€ Data isolation: Client A cannot access Client B's data
â”œâ”€â”€ Compliance: Easier to certify per-client (SOC 2, HIPAA)
â”œâ”€â”€ Blast radius: Issue in Client A doesn't affect Client B
â””â”€â”€ Customization: Different auth policies per client
```

### Failure Scenarios & Disaster Recovery

```
1. LLM API Outage (Anthropic Claude unavailable)
   â”œâ”€â”€ Problem: Weekly batch job cannot generate new recommendations
   â”œâ”€â”€ Mitigation:
   â”‚   â”œâ”€â”€ Fallback: Use recommendations from previous week (7 days stale, acceptable)
   â”‚   â”œâ”€â”€ Circuit breaker: Pause batch job, alert on-call
   â”‚   â”œâ”€â”€ Multi-provider: Fallback to OpenAI GPT-4 if Claude down >1 hour
   â”‚   â””â”€â”€ Cache: Trust scores already computed, auth decisions unaffected
   â””â”€â”€ Impact: Delayed new recommendations (low severity - not critical path)

2. BigQuery Outage (Regional failure)
   â”œâ”€â”€ Problem: Cannot query trust scores, auth decisions blocked
   â”œâ”€â”€ Mitigation:
   â”‚   â”œâ”€â”€ Multi-region replication: us-central1 (primary) + us-east1 (failover)
   â”‚   â”œâ”€â”€ Redis cache: 95% of auth decisions served from cache (unaffected)
   â”‚   â”œâ”€â”€ Degraded mode: Default to current auth step (no optimization)
   â”‚   â””â”€â”€ SLA: 5-minute failover to secondary region
   â””â”€â”€ Impact: 5% of auth decisions delayed (cache misses), but no downtime

3. Trust Score Computation Failure
   â”œâ”€â”€ Problem: Nightly batch job crashes (out of memory, BigQuery timeout)
   â”œâ”€â”€ Mitigation:
   â”‚   â”œâ”€â”€ Checkpointing: Process in batches of 1,000 users, save progress
   â”‚   â”œâ”€â”€ Auto-retry: Retry failed batches 3 times with exponential backoff
   â”‚   â”œâ”€â”€ Fallback: Use yesterday's trust scores (1 day stale)
   â”‚   â””â”€â”€ Alert: Slack notification if batch fails >3 times
   â””â”€â”€ Impact: Trust scores delayed by 1 day (low severity)

4. Security Incident (Account Compromise)
   â”œâ”€â”€ Problem: Reduced auth enabled account takeover for 1 user
   â”œâ”€â”€ Mitigation:
   â”‚   â”œâ”€â”€ Immediate action: Revert user to step 9 auth (maximum security)
   â”‚   â”œâ”€â”€ Investigation: Review trust signals, identify breach vector
   â”‚   â”œâ”€â”€ Rollback: Revert all users in same trust score range to higher auth
   â”‚   â”œâ”€â”€ Alert: PagerDuty notification to security team
   â”‚   â””â”€â”€ Post-mortem: Adjust trust score thresholds to prevent recurrence
   â””â”€â”€ Impact: Single user compromised (contained), broader rollback prevents spread

5. Cost Overrun (LLM costs spike)
   â”œâ”€â”€ Problem: LLM costs jump from $4.5k/month to $45k/month
   â”œâ”€â”€ Mitigation:
   â”‚   â”œâ”€â”€ Budget alerts: Alert at 80% ($3.6k) and 100% ($4.5k) of budget
   â”‚   â”œâ”€â”€ Auto-throttle: Pause batch job if cost >150% of expected
   â”‚   â”œâ”€â”€ Investigation: Check tracing logs for runaway LLM calls
   â”‚   â””â”€â”€ Emergency shutdown: Kill switch to halt all LLM calls if needed
   â””â”€â”€ Impact: Financial, but caught early before significant overspend
```

---

## ğŸ“Š Whiteboard Diagram: Smart Authentication Advisor Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CEO / IT SECURITY DASHBOARD                      â”‚
â”‚  "150 employees waste 6.5 hrs/week on auth. Savings: $2.4M/year."  â”‚
â”‚  "Recommend: Reduce step 8 â†’ step 3 for 150 users (trust score     â”‚
â”‚   >75). Security risk: <1% increase in incidents."                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†‘
                              â”‚ Query (< 2 sec)
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              BIGQUERY (Materialized Views + Tables)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ auth_        â”‚  â”‚ user_trust_  â”‚  â”‚ auth_        â”‚              â”‚
â”‚  â”‚ optimization â”‚  â”‚ scores       â”‚  â”‚ events_raw   â”‚              â”‚
â”‚  â”‚ _recommen-   â”‚  â”‚ (20k rows)   â”‚  â”‚ (365M events)â”‚              â”‚
â”‚  â”‚ dations      â”‚  â”‚              â”‚  â”‚              â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†‘                    â†‘                         â†‘
         â”‚                    â”‚                         â”‚
         â”‚ Write recs         â”‚ Write scores            â”‚ Ingest events
         â”‚ (weekly)           â”‚ (nightly)               â”‚ (real-time)
         â†“                    â†“                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CLOUD RUN JOB      â”‚  â”‚ CLOUD RUN JOB      â”‚  â”‚ PUB/SUB + CLOUD    â”‚
â”‚ "auth-optimizer-   â”‚  â”‚ "trust-score-      â”‚  â”‚ RUN                â”‚
â”‚  batch" (weekly)   â”‚  â”‚  calculator"       â”‚  â”‚ "auth-event-       â”‚
â”‚                    â”‚  â”‚  (nightly)         â”‚  â”‚  processor"        â”‚
â”‚ For 5,000 users:   â”‚  â”‚                    â”‚  â”‚                    â”‚
â”‚ 1. Fetch trust     â”‚â—„â”€â”¤ For 50k users:     â”‚â—„â”€â”¤ Parse SSO events   â”‚
â”‚    signals         â”‚  â”‚ 1. Query 90-day    â”‚  â”‚ Enrich with        â”‚
â”‚ 2. Call Smart Auth â”‚  â”‚    auth history    â”‚  â”‚ metadata           â”‚
â”‚    Advisor (LLM)   â”‚  â”‚ 2. Calculate trust â”‚  â”‚ Write to BigQuery  â”‚
â”‚ 3. Store recommen- â”‚  â”‚    scores (SQL)    â”‚  â”‚                    â”‚
â”‚    dations         â”‚  â”‚ 3. Store in BQ     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                    â”‚  â”‚                    â”‚           â†‘
â”‚ Cost: $1.1k/week   â”‚  â”‚ Cost: $5/day       â”‚           â”‚ Webhooks
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
         â†“                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ 2 LLM calls per user                   â”‚  SSO PROVIDERS    â”‚
         â†“                                        â”‚  (Okta, Google)   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚                   â”‚
â”‚  SMART AUTHENTICATION ADVISOR AGENT        â”‚   â”‚  50M events/day   â”‚
â”‚                                            â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  Tools:                                    â”‚
â”‚  â€¢ query_user_auth_history (BigQuery)      â”‚
â”‚  â€¢ get_device_trust_score (BigQuery)       â”‚
â”‚  â€¢ get_location_trust_score (BigQuery)     â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â€¢ get_behavioral_trust_score (BigQuery)   â”‚   â”‚ REAL-TIME AUTH    â”‚
â”‚  â€¢ recommend_auth_level (LLM)              â”‚   â”‚ DECISION API      â”‚
â”‚  â€¢ explain_decision (LLM)                  â”‚   â”‚ (Cloud Run)       â”‚
â”‚                                            â”‚   â”‚                   â”‚
â”‚  Output: Recommended auth step +           â”‚   â”‚ User Login        â”‚
â”‚          Confidence + Reasoning +          â”‚   â”‚    â†“              â”‚
â”‚          Time Savings + Security Risk      â”‚   â”‚ Lookup trust      â”‚
â”‚                                            â”‚   â”‚ score (Redis)     â”‚
â”‚  Example:                                  â”‚   â”‚    â†“              â”‚
â”‚  "Reduce step 8 â†’ 2. Confidence: 92%.      â”‚   â”‚ Simple rules:     â”‚
â”‚   Trust score: 86/100. Trusted device      â”‚   â”‚ IF score>85:      â”‚
â”‚   at office. No failures in 60 days.       â”‚   â”‚   step=2          â”‚
â”‚   Time savings: 3.5 min/auth. Annual:      â”‚   â”‚    â†“              â”‚
â”‚   $3k for this user. Security risk: Very   â”‚   â”‚ Return to Okta    â”‚
â”‚   Low."                                    â”‚   â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ Latency: <100ms   â”‚
         â†“                                       â”‚ (NO LLM in path!) â”‚
         â”‚ All LLM calls traced                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TRACING & MONITORING                      â”‚
â”‚  â€¢ Cost: $4.5k/month (LLM)                 â”‚
â”‚  â€¢ Latency: p95 < 3 sec (batch job)        â”‚
â”‚  â€¢ Accuracy: >85% (vs IT labels)           â”‚
â”‚  â€¢ Security: <1% incident increase         â”‚
â”‚  â€¢ Alerts: Slack/PagerDuty                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—£ï¸ Common Interview Questions & Answers

### Q: "How do you ensure this doesn't compromise security?"

**A:** "Excellent question - security is non-negotiable. Here's our multi-layered approach:

**1. Conservative Trust Score Thresholds:**

- Only recommend auth reduction for trust score â‰¥75/100 (top quartile)
- Never reduce auth below step 2 (password + occasional MFA)
- Finance/executive teams flagged for manual review (never auto-reduce)

**2. Continuous Monitoring:**

- Alert if trust score drops >20 points for any user â†’ auto-revert to higher auth
- Alert if failed auth attempts spike >2Ã— â†’ investigate potential compromise
- Velocity flags trigger immediate step-up auth (unusual location = high risk)

**3. Human-in-the-Loop (Approval Workflow):**

- Agent generates recommendations weekly
- CISO reviews dashboard, approves/rejects before enforcement
- Can override individual users or entire categories

**4. A/B Testing with Security Metrics:**

- Control group maintains current auth (baseline security incidents)
- Treatment group gets reduced auth (monitor for >1% increase in incidents)
- If security degrades, rollback immediately

**5. Audit Trail:**

- Every auth decision logged with reasoning
- Can trace: 'Why was User X allowed step 2 on Jan 15 at 9 AM?'
- Answer: 'Trust score 86, trusted device for 120 days, office WiFi, work hours'

**Target:** <1% increase in security incidents (acceptable trade-off for 40% time savings)"

---

### Q: "What if users intentionally game the system to get lower auth?"

**A:** "Great question - adversarial behavior is a real concern. Here's how we handle it:

**Scenario: User tries to game trust score**

```
User thinks: 'If I use the same device and location for 90 days,
             I'll get lower auth. Then I'll switch to a new device
             and the system won't catch it.'
```

**Our Defense:**

1. **Step-up auth on device change:**

   - New device detected â†’ immediately revert to step 8 (max security)
   - Must rebuild trust over 30+ days on new device

2. **Location change detection:**

   - Unusual location (>100 miles from typical) â†’ step up to step 6
   - Velocity flag (impossible travel) â†’ step up to step 9

3. **Behavioral anomalies:**

   - Access at unusual time (3 AM when user typically works 9-5) â†’ step up
   - Weekend access (when user never works weekends) â†’ step up

4. **Trust score is dynamic, not static:**

   - Recalculated nightly based on last 90 days (rolling window)
   - One failure â†’ trust score drops 5 points
   - Unusual access pattern â†’ trust score drops 10 points

5. **Failed auth attempts reset trust:**
   - Failed auth â†’ trust score drops to 0, revert to step 9
   - Must rebuild trust over 60 days with no failures

**Example:**

```
User has trust score 85, step 2 auth
User tries to login from new laptop at 3 AM from Las Vegas
  â†’ System detects:
     â€¢ New device (not in 90-day history)
     â€¢ Unusual time (3 AM, user works 9-5)
     â€¢ Velocity flag (impossible travel from SF to Vegas in 2 hours)
  â†’ Action: Revert to step 9 immediately, alert security team
```

**Gaming is very hard because:**

- Trust is earned over 90 days, lost in 1 failure
- Any deviation from pattern triggers step-up
- Security team can flag users for manual review"

---

### Q: "How does this scale to 500k users across 50 clients?"

**A:** "Great question - let me break down the scaling strategy:

**Current Demo:** 18 events, 10 users
**Production Scale:** 50M auth events/day, 500k users

**Bottlenecks & Solutions:**

**1. LLM Costs**

```
Naive approach: Categorize every user weekly
  500k users Ã— $0.015 Ã— 4 weeks = $30k/month âŒ Too expensive

Optimized approach: Only categorize high-friction users
  500k Ã— 15% high-friction = 75k users
  75k Ã— $0.015 Ã— 4 weeks = $4.5k/month âœ… Reasonable

Further optimization: Only recategorize on significant trust score change
  75k Ã— 30% with score change = 22.5k users/week
  22.5k Ã— $0.015 Ã— 4 weeks = $1.35k/month âœ… Very cheap
```

**2. BigQuery Query Costs**

```
Problem: Querying 50M events/day Ã— 365 days = 18B events
Solution:
  â”œâ”€â”€ Partition by date (only scan last 90 days, not all 18B)
  â”œâ”€â”€ Cluster by user_id + device_id (100Ã— faster queries)
  â”œâ”€â”€ Materialize trust scores (pre-compute nightly, don't recalculate on-demand)
  â””â”€â”€ BI Engine: Cache 10 GB hot data in-memory

Cost reduction: $50k/month â†’ $1k/month (50Ã— cheaper)
```

**3. Real-Time Auth Latency**

```
Problem: Cannot call LLM during auth (2-second latency)
Solution:
  â”œâ”€â”€ Pre-compute trust scores nightly (cheap SQL)
  â”œâ”€â”€ Cache in Memorystore Redis (1-hour TTL)
  â”œâ”€â”€ Real-time auth decision = simple lookup (< 100ms)
  â””â”€â”€ LLM only used for weekly batch recommendations (offline)

Result: 95% cache hit rate, 5ms avg latency âœ…
```

**4. Data Pipeline**

```
Current: 50M events/day
10Ã— growth: 500M events/day

Solutions:
  â”œâ”€â”€ Pub/Sub auto-scales (handles billions of messages)
  â”œâ”€â”€ Cloud Run auto-scales (0-100 instances based on traffic)
  â”œâ”€â”€ BigQuery streaming inserts (1M rows/sec per table)
  â””â”€â”€ Shard by tenant_id (each client isolated, parallel processing)

Cost at 10Ã— scale: $85k/month (still $0.017/user/month) âœ…
```

**5. Client Isolation**

```
50 clients Ã— 10k users = 500k users
Each client in isolated GCP project:
  â”œâ”€â”€ Dedicated BigQuery dataset
  â”œâ”€â”€ Dedicated Cloud Run services
  â”œâ”€â”€ Dedicated Redis cache
  â””â”€â”€ Shared pipeline code (parameterized by tenant_id)

Benefits:
  â”œâ”€â”€ Data isolation (no cross-tenant leakage)
  â”œâ”€â”€ Compliance (easier to certify per-client)
  â””â”€â”€ Blast radius (issue in Client A doesn't affect Client B)
```

**Scaling Summary:**

- **LLM costs:** Scale sub-linearly (only high-friction users)
- **BigQuery:** Partition + cluster pruning = constant cost
- **Latency:** Redis caching = constant latency
- **Infrastructure:** Auto-scaling handles 10Ã— growth seamlessly
- **Cost per user:** $0.016-0.018/month (stays constant even at 10Ã— scale)"

---

### Q: "How would you roll this out to existing Parable clients?"

**A:** "Great question - rolling out auth changes to Fortune 1000 companies requires extreme care. Here's my phased approach:

**Phase 1: Shadow Mode (Week 1-2)**

```
Goal: Validate accuracy without affecting users
Actions:
â”œâ”€â”€ Deploy to 1 pilot client (5k employees)
â”œâ”€â”€ Run Smart Authentication Advisor in shadow mode:
â”‚   â””â”€â”€ Generate recommendations BUT don't enforce them
â”‚   â””â”€â”€ Log: 'Would have reduced User X from step 8 â†’ 2'
â”œâ”€â”€ Compare agent recommendations to:
â”‚   â”œâ”€â”€ IT security team's manual review (100 users)
â”‚   â””â”€â”€ Historical auth patterns (would reduction have been safe?)
â””â”€â”€ Measure: Accuracy >85%, CISO agreement >85%

Success criteria:
â”œâ”€â”€ No false positives (recommending low auth for high-risk users)
â”œâ”€â”€ IT team comfortable with reasoning quality
â””â”€â”€ CEO dashboard shows clear ROI ($500k/year for 5k employees)
```

**Phase 2: Limited Rollout (Week 3-4)**

```
Goal: Implement for small, low-risk cohort
Actions:
â”œâ”€â”€ Same pilot client (5k employees)
â”œâ”€â”€ Identify safest cohort:
â”‚   â””â”€â”€ Engineers on trusted devices (lowest risk)
â”‚   â””â”€â”€ ~50 employees (1% of org)
â”œâ”€â”€ Implement reduced auth for this cohort
â”œâ”€â”€ Monitor closely:
â”‚   â”œâ”€â”€ Failed auth attempts (should remain flat)
â”‚   â”œâ”€â”€ Security incidents (must be 0)
â”‚   â”œâ”€â”€ User feedback ('Was auth easier today?')
â”‚   â””â”€â”€ Time savings (measure actual auth time reduction)
â””â”€â”€ Duration: 2 weeks

Success criteria:
â”œâ”€â”€ 0 security incidents
â”œâ”€â”€ >40% auth time reduction
â”œâ”€â”€ >4.0/5 user satisfaction
â””â”€â”€ IT team reports no issues
```

**Phase 3: Graduated Rollout (Week 5-8)**

```
Goal: Expand to entire pilot client
Strategy: 10% per week

Week 5: 10% (500 employees) - Engineers
Week 6: 30% (1,500 employees) - + Product/Design
Week 7: 60% (3,000 employees) - + Sales/Marketing
Week 8: 100% (5,000 employees) - All employees
          (excluding Finance/Exec = keep step 8)

Monitoring at each stage:
â”œâ”€â”€ Failed auth rate (baseline: 0.5%, alert if >1%)
â”œâ”€â”€ Security incidents (baseline: ~1/month, alert if >2)
â”œâ”€â”€ User satisfaction (survey weekly)
â””â”€â”€ IT support tickets (should decrease)

Rollback plan:
â””â”€â”€ If any metric degrades >20%, pause rollout at current %
```

**Phase 4: Multi-Client Expansion (Week 9-20)**

```
Goal: Scale to 5 clients (beta group)
Clients: Mix of industries (tech, finance, healthcare, retail, manufacturing)

Week  9-10: Client 2 (tech company, low-risk)
Week 11-12: Client 3 (retail, medium-risk)
Week 13-14: Client 4 (healthcare, high-risk - extra caution)
Week 15-16: Client 5 (finance, high-risk - conservative thresholds)
Week 17-20: Iterate based on feedback, tune prompts per industry

Learnings:
â”œâ”€â”€ Healthcare needs different trust thresholds (stricter)
â”œâ”€â”€ Finance requires manual CISO approval (cannot auto-apply)
â”œâ”€â”€ Tech companies want aggressive optimization (willing to take more risk)
â””â”€â”€ Update prompts with industry-specific guidance
```

**Phase 5: Full Rollout (Week 21-52)**

```
Goal: All 50 clients (500k users)
Strategy: 5 clients/month

Automation:
â”œâ”€â”€ Client onboarding playbook (IT setup, CEO training)
â”œâ”€â”€ Self-service dashboard (clients can tune thresholds)
â”œâ”€â”€ Automated monitoring (alert per-client if issues)
â””â”€â”€ Weekly status reports to Parable leadership

Success metrics after 6 months:
â”œâ”€â”€ 50 clients live (500k users)
â”œâ”€â”€ $2.4M/year avg savings per 1,000-employee org
â”œâ”€â”€ <1% security incident increase across all clients
â””â”€â”€ >90% client satisfaction (renewal rate)
```

**Key Principles:**

1. **Start small:** 1% â†’ 10% â†’ 100% (minimize risk)
2. **Measure everything:** Security, productivity, satisfaction
3. **Rollback ready:** Can revert to higher auth within minutes
4. **Client-specific:** Finance needs stricter thresholds than tech
5. **Transparency:** Show IT team every recommendation with reasoning

This phased approach ensures we deliver productivity gains without compromising security for Fortune 1000 clients."

---

## âœ… Interview Readiness Checklist

**System Design Fundamentals:**

- [ ] I can draw the Smart Authentication Advisor architecture on a whiteboard
- [ ] I can explain all 7 key areas (business, agent, pipeline, RBAC, evaluation, tracing, scale)
- [ ] I can calculate costs for 500k users ($8-9k/month, $0.016-0.018/user)
- [ ] I can discuss latency optimization (<100ms auth decision, <2 sec dashboard)

**Agentic Workflows:**

- [ ] I can explain why agentic > ML for auth optimization (explainability, adaptability)
- [ ] I can design the agent with tools, LLM prompting, and flow
- [ ] I can describe natural language outputs for users AND IT
- [ ] I can discuss evaluation (IT labels, CISO agreement, A/B security test)

**Production Engineering:**

- [ ] I can describe BigQuery architecture (partitioning, clustering, trust score caching)
- [ ] I can explain single-tenant isolation per Fortune 1000 client
- [ ] I can design RBAC matrix (CEO, CISO, manager, employee access)
- [ ] I can describe LLM tracing (cost, latency, tokens, prompt version)

**Security & Privacy:**

- [ ] I can discuss security safeguards (step-up auth, monitoring, rollback)
- [ ] I can handle "how do you ensure this doesn't compromise security?" question
- [ ] I can explain PII handling (hashed IDs, anonymized IPs, GDPR compliance)
- [ ] I can describe approval workflow (human-in-the-loop, CISO review)

**Scale & Performance:**

- [ ] I can discuss 50M auth events/day processing (partitioning, caching)
- [ ] I can optimize auth decision latency (<100ms with Redis caching)
- [ ] I can calculate LLM costs at scale ($4.5k/month for 75k users)
- [ ] I can handle 10Ã— scale growth question (sub-linear cost scaling)

**Interview Flow:**

- [ ] I can smoothly transition from data analysis to system design
- [ ] I can handle common questions (security, gaming, scaling, rollout)
- [ ] I can reference the 5 CEO questions throughout
- [ ] I can quantify ROI for every design decision ($2.4M/year savings)

**Parable-Specific:**

- [ ] I can discuss this as Hypothesis 2.1 (strongest signal in sample data)
- [ ] I know their tech stack (GCP, TypeScript, BigQuery, single-tenant)
- [ ] I can frame system design through organizational observability lens
- [ ] I can emphasize CEO-facing insights and Fortune 1000 scale

---

**You're now ready to discuss the Smart Authentication Advisor system design in your Parable interview!**
